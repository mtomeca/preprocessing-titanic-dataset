---
title: "Titanic Project (Kaggle)"
author: "Guillem Fernández Pallarès i Miquel Tomé Carreño"
date: "`r format(Sys.Date(),'%e de %B, %Y')`"
output:
  html_document:
    df_print: paged
    toc: yes
  pdf_document:
    number_sections: yes
    toc: yes
header-includes: \DeclareUnicodeCharacter{0007}{}
toc-title: Índex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Packages to import
library("kableExtra")
library("tidyr")
library("party")
library("rpart")
library("rpart.plot")
library("corrplot")
library("pROC")
library("nortest")
```

# 1. Descripció del dataset

El dataset escollit ha estat *Titanic: Machine Learning from Disaster* disponible [a aquest enllaç](https://www.kaggle.com/c/titanic/data). Amb aquest joc de dades es pretenen aplicar algorismes de Machine Learning posteriors al preprocessat de les dades per crear models predictius que permetin construir un model que prevegui, en funció d'unes variables determinades, un determinat passatger sobreviurà o no al conegut accident.

El dataset descarregat es composa de 3 fitxers, els quals es troben en format `csv`.

El primer fitxer, `gender_submission.csv`, és un exemple del fitxer resultant a presentar un cop realitzat l'exercici, i conté una relació dels passatgers que van sobreviure amb dues columnes: identificador del passatger i el sexe (0 = Dona i 1 = Home). 

Els altres dos fitxers contenen el conjunt de dades que ens serviran per entrenar l'algorisme (conjunt `train.csv`) i les dades de test (conjunt `test.csv`) que ens serviran per calcular el nivell de precisió en les prediccions del nostre algorisme i que seran les dades que haurem d'entregar per tal que se'ns valori en la competició de Kaggle.

Les variables que podem trobar tant al fitxer train.csv com al de test.csv, són les següents:

- **survival**: Variable dicotòmica que expressa si el passatger va sobreviure (valor 1) o no (valor 0).
- **pclass**: Variable que expressa la categoria en la que viatjava el passatger (primera, segona o tercera).
- **sex**: Ens indica si el passatger era un home (valor 1) o una dona (valor 0).
- **age**: Edat del passatger en anys.
- **sibsp**: El número de germans que hi tenia al vaixell o si hi havia el seu espòs o muller. En cas que aquesta variable sigui 1, no tindrem capacitat per esbrinar si es tracta d'un germà o de la parella.
- **parch**: Semblant a la variable anterior, expressa quants fills més hi havia al vaixell o, en cas de ser un infant, quants pares l'acompanyaven.
- **ticket**: El número de bitllet que tenia el passatger. Equivaldria a un Id del bitllet.
- **fare**: El cost del bitllet que havia pagat el passatger.
- **cabin**: El número de cabina on s'allotjava el passatger. Equivaldria a un Id de la cabina.
- **embarked**: El port on va embarcar el passatger. En aquest cas hi tenim 3 possibilitats (C = Cherbourg, Q = Queenstown i S = Southampton).

En una primera inspecció, veiem que el conjunt d'entrenament consta de 891 registres, mentre que el de test en té 418. Podríem dir doncs, que per separar els registres entre el conjunt de test i el d'entrenament el mètode que més s'hi aproxima és el *k-fold cross validation* amb una k=3, essent la *regla dels dos terços*, la qual utilitza dos conjunts per l'entrenament i un pel test.

# 2. Integració i selecció de dades

Les dades utilitzades es troben dividides en dos datasets diferents: un d'ells conté el subconjunt de dades que serà utilitzat al set d'entrenament o *training set* i l'altre conté aquelles que seran utilitzades al test de prova o *testing set* per comprovar l'eficàcia del model construït. Els dos subconjunts s'integraran en un de sol per facilitar el recompte de valors perduts que presenten.

Primerament, es llegiran ambdós fitxers i s'afegirà una columna a cadascun d'ells que indicarà si un determinat registre pertany al subconjunt d'entrenament o de prova. Addicionalment, cal esmentar que al subset de prova s'ha afegit la columna `Survived` amb valors perduts `NA`, que és la variable dicotòmica a predir i que està present a l'altre subset.

Pel que fa a la selecció de les dades, es trindran en compte la totalitat de registres dels quals es disposa, els quals seran considerats durant la fase de preprocessat de les dades. No obstant, es descartaran les variables categòriques que es considera que no aporten cap tipus d'informació a l'anàlisi: `Name`, `Ticket` i `Cabin`.

```{r read files}
# Lectura del training set.
r_train <- read.csv("train.csv")
head(r_train)
# Lectura del testing set i addició de la variable a predir.
r_test <- read.csv("test.csv")
r_test$Survived <- NA
head(r_test)
# Addició de la columna amb la classificació train-test.
r_train$train_test <- "train"
r_test$train_test <- "test"
# Eliminació de les columnes que no són d'interès.
r_train[,c("Name","Ticket","Cabin")] <- NULL
r_test[,c("Name","Ticket","Cabin")] <- NULL
# Concatenació dels dos subsets.
data <- rbind(r_train,
              r_test)
# Comprovació que s'ha concatenat correctament.
nrow(r_train) + nrow(r_test) == nrow(data)
```

# 3. Neteja de les dades

El següent pas a dur a terme abans de l'anàlisi de les dades, és la neteja i preprocessat d'aquestes. En els dos següents apartats es realitzarà un breu estudi per determinar si existeixen valors perduts i/o valors extrems.

## 3.1. Valors perduts

Primerament, s'inspeccionaran les dades de les quals es disposa amb la finalitat de trobar els valors perduts. Es consideraran tant els que tenen associat el valor `NA` com els que tenen camps en blanc, a més a més d'estudiar la versemblança de les variables numèriques que prenen valor 0. Addicionalment, es comprovarà que els `NA` introduïts manualment a la variable `Survived` en apartats anteriors es corresponen a la totalitat de valors perduts de la columna, és a dir, es comprovarà que la variable que es vol predir no contingui valors perduts al subset d'entrenament de l'algorisme.

```{r missing values}
# Total de valors perduts o buits al dataset.
for (i in 1:ncol(data)-1) {
  cat("\nLa columna",
      colnames(data[i]),
      "presenta",
      sum(is.na(data[,i]) | data[,i] == ""),
      "valors nuls o buits.")
}
# Comprovació que les dades d'entrenament no tenen valors perduts a Survived.
cat("\n\nLa suma de valors perduts per al conjunt d'entrenament són:",sum(is.na(data$Survived[data$train_test == "train"])))
# Total de zeros a cada columna del dataset.
for (i in 1:ncol(data)-1) {
  cat("\nLa columna",
      colnames(data[i]),
      "presenta",
      sum(data[,i] == 0, na.rm = T),
      "zeros.")
}
```

Com es pot observar, les columnes que contenen valors perduts són `Survived` (tot i que es corresponen amb els assignats manualment), `Age`, `Fare` i `Embarked`. Es tractaran diferentment en funció del seu format.

* Els valors perduts de la variable `Survived` es deixaran sense tractar, ja que corresponen als que han estat inserits manualment a la columna per tal de poder ajuntar el subset d'entrenament i el de prova. Posteriorment, es descartarà aquesta variable quan es torni a separar els dos subconjunts de dades.
* A les variables `Age` i `Fare`, ambdues numèriques, es substituiran els valors perduts per la mediana de la variable. Es tria aquesta opció perquè la mediana és una mesura de tendència central menys sensible a valors extrems que la mitjana.
* La columna `Embarked`, corresponent al port on va embarcar el passatger en qüestió, conté una variable categòrica que no pot ser ordenada en ordre creixent o decreixent, com podria fer-se amb una variable numèrica. Per tant, en aquest cas s'associarà als valors perduts d'aquesta columna el valor més freqüent.

Paral·lelament, també s'han observat valors numèrics nuls (0s) a les variables `Survived`, `SibSp`, `Parch` i `Fare`. Aquests casos es tractaran de la següent manera:

* Els zeros de la variable `Survived` es consideren coherents, ja que aquests fan referència a un dels dos factors de la variable dicotòmica que indica si el passatger va sobreviure o no a l'accident. Per aquest motiu, no es considera necessari tractar-los.
* Els zeros de les variables `SibSp` i `Parch` es consideren adequats, ja que és possible que hi hagués passatgers a bord sense que el seu germà o parella hi fos, de la mateixa manera que hi poden haver passatgers sense fills o fills que viatgéssin sols.
* Els zeros de la variable `Fare` hauran de ser tractats, ja que es considera impossible el fet que hi hagi passatgers que viatgen gratuïtament. De la mateixa manera que s'ha decidit fer amb els valors buits, els 0 es substitueixen per la mediana de la variable. Es realitzarà abans aquesta substitució que la de valors buits per calcular correctament la mediana.

Es crearà una funció per tal de facilitar el preprocessat de les dades que pertanyen als dos subconjunts, el d'entrenament i el de prova.

```{r treat missing values v2}
clean_transform <- function(x){
  
  # Neteja i transformació de la variable Sex.
  x$Sex_Numeric <- as.character(x$Sex)
  x$Sex_Numeric[x$Sex_Numeric=="male"] <- "0"
  x$Sex_Numeric[x$Sex_Numeric=="female"] <- "1"
  x$Sex_Numeric <- as.integer(x$Sex_Numeric)
  
  # Passem la variable Age a Integer i als valors buits els associem la mediana.
  # Els valors entre 0 i 1 es converteixen tots a 1.
  x$Age <- as.integer(x$Age)
  x$Age[is.na(x$Age) | x$Age == ""] <- median(x$Age, na.rm = TRUE)
  x$Age[x$Age==0] <- 1
  
  # Els valors buits o NA de Fare es substitueixen per la mediana, així com els 0s.
  x$Fare[x$Fare == 0] <- median(x$Fare, na.rm = TRUE)
  x$Fare[is.na(x$Fare) |
           x$Fare == ""] <- median(x$Fare, na.rm = TRUE)
  
  # Els valors buits o NA de Embarked els hi associem el valor més freqüent.
  x$Embarked[is.na(x$Embarked) |
               x$Embarked == ""] <- names(which.max(table(r_train$Embarked,
                                                          useNA="no")))
  
  # Convertim la variable Embarked a numèrica
  x$Embarked_Numeric <- as.character(x$Embarked)
  x$Embarked_Numeric[x$Embarked_Numeric=="C"] <- "1"
  x$Embarked_Numeric[x$Embarked_Numeric=="Q"] <- "2"
  x$Embarked_Numeric[x$Embarked_Numeric=="S"] <- "3"
  x$Embarked_Numeric <- as.integer(x$Embarked_Numeric)
  
  # Convertim la variable dependent Survived a factor.
  if("Survived" %in% colnames(x)) {
    x$Survived <- as.character(x$Survived)
    x$Survived[x$Survived=="0"] <- "Died"
    x$Survived[x$Survived=="1"] <- "Survived"
    x$Survived <- as.factor(x$Survived)
  } else {
    
  }
  return(x)
}
# Subconjunt d'entrenament.
titanic_train_clean <- clean_transform(r_train)
head(titanic_train_clean[, c("Survived", "Age", "Fare", "Sex_Numeric", "Pclass", "Embarked_Numeric")])
# Subconjunt de prova.
titanic_test_clean <- clean_transform(r_test)
head(titanic_test_clean[, c("Age", "Fare", "Sex_Numeric", "Pclass", "Embarked_Numeric")])
```

## 3.2. Valors extrems o *outliers*

El següent pas a dur a terme en la fase de la neteja de dades és la identificació i el posterior tractament de valors extrems o *outliers*. Per tal d'identificar aquests valors i veure una representació gràfica de la proporció de registres que representen i com es distribueixen, es realitzaran diagrames de caixes o *boxplots* per les variables numèriques que cal analitzar: `Age`, `SibSp`, `Parch` i `Fare`.
          
```{r boxplots}
# Boxplot per la variable Age.
boxplot(titanic_train_clean$Age,
        main="Distribució variable Age")
# Boxplot per SibSp i Parch.
boxplot(titanic_train_clean[c("SibSp", "Parch")],
        main="Distribució variable Siblings/Spouse i Parch")
# Boxplot per Fare.
boxplot(titanic_train_clean$Fare,
        main="Distribució variable Fare")
```

Als gràfics obtinguts es pot observar el següent:

* Les dues primeres representacions, tot i mostrar punts que es podrien considerar valors extrems, s'observen valors raonables d'acord amb la magnitud o realitat que representen. Per aquest motiu, no se'ls descartarà ni es tractaran de cap manera.
* L'última figura, corresponent a la variable `Fare`, mostra dos grups considerablement allunyats de la caixa representada. Es considera que aquests punts podrien contenir algun tipus d'error i es decideix reassignar el seu valor pel de la mediana de la variable.

```{r outliers Fare}
# Tractament dels outliers de la variable Fare.
titanic_train_clean$Fare[titanic_train_clean$Fare > 200] <-
  median(titanic_train_clean$Fare, na.rm = TRUE)
# Boxplot per Fare.
boxplot(titanic_train_clean$Fare,
        main="Distribució variable Fare")
```

# 4. Anàlisi de les dades

## 4.1. Planificació dels anàlisis

En aquesta secció es realitzaran diverses proves que permetran conèixer amb una major profunditat l'aparença i el comportament col·lectiu de les dades de les quals es disposa per posteriorment aplicar algorismes que permetin la construcció de models que puguin predir si un determinat passatger, en funció d'algunes de les variables de les quals es disposa, va sobreviure o no a l'accident que va patir el Titanic.

Primerament, es construirà una matriu de correlació que permetrà conèixer com es correlacionen entre elles les diferents variables que s'ha decidit analitzar del dataset. A continuació, s'aplicaran dos algorismes supervisats per intentar predir el resultat o *outcome* de la variable `Survived`:

1. Un arbre de decisió o *decision tree*.

2. Una regressió logística.

No obstant, abans de començar amb la part que comprèn estrictament l'anàlisi de dades, cal dur a terme una inspecció introductòria del comportament de les dades de les quals es disposa. Per aquest motiu, a continuació s'estudiarà la normalitat i homoscedasticitat del dataset.

## 4.2. Comprovació de la normalitat i l'homoscedasticitat

Per a fer l'estudi de la normalitat, analitzarem les variables que finalment hem seleccionat per construir el nostre model. Farem l'estudi comprovant si aquelles variables contínues que es troben en els conjunts de dades de train i test presenten una distribució normal o no. Les variables contínues que té sentit que analitzem des d'un punt de vista de distribució normal són `Age` i `Fare`.

En primer lloc, farem la representació des d'un punt de vista visual a partir d'histogrames amb les línies de denisitat corresponents.

```{r}
hist(titanic_train_clean$Age, freq = F, ylim = c(0, 0.08), border = "gray50", xlab = "Variable Age", main = "Distribució variable Age (Conjunt Train)")
lines(density(titanic_train_clean$Age))
curve(dnorm(x, mean(titanic_train_clean$Age), sd(titanic_train_clean$Age)), col = "blue", add = T)
legend("topright", c("curva observada", "curva teòrica"),
       lty = 1, lwd = 2, col = c("black", "blue"), bty = "n", cex = 0.8)
```

```{r}
hist(titanic_train_clean$Age, freq = F, ylim = c(0, 0.06), border = "gray50", xlab = "Variable Fare", main = "Distribució variable Fare (Conjunt Train)")
lines(density(titanic_train_clean$Fare))
curve(dnorm(x, mean(titanic_train_clean$Fare), sd(titanic_train_clean$Fare)), col = "blue", add = T)
legend("topright", c("curva observada", "curva teòrica"),
       lty = 1, lwd = 2, col = c("black", "blue"), bty = "n", cex = 0.8)
```


Repetim els gràfics per les variables del conjunt de test.

```{r}
hist(titanic_test_clean$Age, freq = F, ylim = c(0, 0.08), border = "gray50", xlab = "Variable Age", main = "Distribució variable Age (Conjunt Test)")
lines(density(titanic_test_clean$Age))
curve(dnorm(x, mean(titanic_test_clean$Age), sd(titanic_test_clean$Age)), col = "red", add = T)
legend("topright", c("curva observada", "curva teòrica"),
       lty = 1, lwd = 2, col = c("black", "red"), bty = "n", cex = 0.8)
```


```{r}
hist(titanic_test_clean$Fare, freq = F, ylim = c(0, 0.04), border = "gray50", xlab = "Variable Fare", main = "Distribució variable Fare (Conjunt Test)")
lines(density(titanic_test_clean$Fare))
curve(dnorm(x, mean(titanic_test_clean$Fare), sd(titanic_test_clean$Fare)), col = "red", add = T)
legend("topright", c("curva observada", "curva teòrica"),
       lty = 1, lwd = 2, col = c("black", "red"), bty = "n", cex = 0.8)
```

Una altra manera de fer la representació gràfica és usant els QQ-Plots. En aquest cas farem un QQ-plot per la variable *Age* i un altre per la variable *Fare*.

```{r}
# QQPlot Age
qqnorm(r_test$Age)
qqnorm(r_train$Age)
```

Per a la variable *Age*, tant del conjunt test com d'entrenament, a partir del gràfic QQ-Plot veiem que no acaba d'ajustar molt a una distribució normal, especialment pels valors inicials que es situen a la zona inferior esquerra. La resta de valors sí que segueixen una línia molt més recta, i per tant, tenen una aproximació a la normal.

```{r}
# QQPlot Age
qqnorm(r_test$Fare)
qqnorm(r_train$Fare)
```

Pel que fa a la variable *Fare*, tant del conjunt test com train, aquest desajust a la normal és encara més gran. Veiem que no segueix cap tipus de línia recta, indicant-nos que no segueix una distribució normal.

Un cop fetes les representacions gràfiques, es durà a terme aquesta comprovació des d'un pust de vista estadístic, realitzant dos tests: aplicarem el test de Shapiro i el test de Lillie. Per ambdues proves prendrem un nivell de confiança del 95%, essent el nostre nivell de significació alfa de $\alpha=0.05$. Així doncs, si el p-valor és inferior a 0.05, no podrem garantir ni assegurar que les nostres variables segueixin una distribució normal. Per altra banda, si el p-valor és superior a 0.05, afirmarem que segueixen una distribució normal.

```{r}
# Apliquem Shapiro Test a les variables del conjunt de train
shapiro.test(titanic_train_clean$Age)
shapiro.test(titanic_train_clean$Fare)
# Apliquem Shapiro Test a les variables del conjunt de test
shapiro.test(titanic_test_clean$Age)
shapiro.test(titanic_test_clean$Fare)
```

Segons el test de Shapiro, cap de les dues variables segueix una distribució normal, ni pel conjunt d'entrenament ni pel de prova. Tots els p-values estan per sota del nivell de significació del 0.05.

```{r}
# Apliquem Lillie Test a les variables del conjunt de train
lillie.test(titanic_train_clean$Age)
lillie.test(titanic_train_clean$Fare)
# Apliquem Lillie Test a les variables del conjunt de test
lillie.test(titanic_test_clean$Age)
lillie.test(titanic_test_clean$Fare)
```

Si ho verifiquem amb el Lillie test, veiem que segons aquest les dades tampoc segueixen una distribució normal ni pel conjunt de train ni pel de test. Tots els p-values estan per sota del nivell de significació del 0.05.

*Variàncies*

Pel que fa a les variàncies és important comprovar si les del conjunt d'entrenament i test són estadísticament semblants. Per tant, utilitzarem la funció var.test() per comprovar si es produeix homoscedasticitat o no entre les variables numèriques contínues que volem utilitzar per predir la variable *Survived*. Aquestes variables són: Age i Fare.

```{r}
# Comencem amb Age
var.test(r_test$Age, r_train$Age)
```

Per la variable *Age* obtenim un p-valor de 0.6183, el qual ens explica que no hi ha una diferència significativa entre les variàncies de la variable *Age* pel conjunt de test i entrenament.

Repetim el procés amb *Fare*.

```{r}
# Ho apliquem a Fare
var.test(r_test$Fare, r_train$Fare)
```

Ara bé, per la variable *Fare* obtenim un valor de 0.004, la qual cosa ens obliga a rebutjar la hipòtesis nul·la d'igualtat de variàncies, i hem de considerar que les variàncies són diferents (heteroscedasticitat).

## 4.3. Aplicació dels mètodes d'anàlisis de dades

### 4.3.1. Matriu de correlació

Abans de començar a plantejar els algorismes que s'implantaran, es farà un breu estudi sobre la correlació entre les múltiples variables que comprèn el dataset. Concretament, es construirà una matriu de correlació en el qual cadascun dels elements de la matriu correspondrà a la correlació de Pearson entre dues variables. Cal esmentar que tan sols s'utilitzaran les variables numèriques de les quals es disposa, tant les manipulades com les que eren numèriques inicialment.

```{r correlation matrix}
# Matriu de correlació.
corr <-cor(titanic_train_clean[,c("Age", "Fare", "Sex_Numeric", "Pclass",
                                  "SibSp", "Parch", "Embarked_Numeric")], method = c("pearson"))
corrplot(corr, method="circle")
```

Un cop vista la corrrelació entre les variables que disposem en el nostre dataset, decidim utilitzar `Age`, `Fare`, `Sex_Numeric`, `Embarked_Numeric` i `Pclass`. Certament, veiem que les variables `Fare` i `Pclass` estan considerablement correlacionades i podríem decidir només passar-ne una. Tot i això, en aquest cas no ens suposa un problema d'alt cost computacional passar totes les variables, i per tant no necessitem fer una reducció de dimensionalitat.

### 4.3.2. Arbre de decisió

El primer algorisme que s'implantarà per tal de construir un model que pugui predir la supervivència d'un passatger a l'accident del Titanic serà un arbre de decisió. Aquest model predirà la variable de resposta `Survived` en funció de les variables explicatives `Age`, `Fare`, `Sex_Numeric`, `Embarked_Numeric` i `Pclass`.

A continuació es mostra la representació gràfica de l'arbre generat i, posteriorment, s'efectua la predicció sobre el subconjunt d'entrenament.

```{r}
# Arbre de decisió.
tree <- rpart(Survived ~., data = titanic_train_clean[,c("Survived", "Age", "Fare", "Sex_Numeric", "Embarked_Numeric", "Pclass")])
rpart.plot(tree)
# Predicció train.
train_prediction <- predict(tree, titanic_train_clean[,c("Survived", "Age", "Fare", "Sex_Numeric", "Embarked_Numeric", "Pclass")], type = 'class')
```

La forma correcta d'interpretar l'arbre de decisió representat és la següent:

1. El node superior mostra que la probabilitat global de supervivència és del 41%. A més a més, en aquest node es pregunta si el sexe del passatger és home (0) o dona (1).

2. En cas de ser home (`Sex_Numeric=0`), les probabilitats de sobreviure són del 19%, mentre que si és una dona les probabilitats ascendeixen a un 74%, tal com mostren ambdues branques.

3. Es procedeix anàlogament per les diferents branques que constitueixen l'arbre i que es regeixen per les variables `Pclass`, `Age` i `Fare`.

Seguidament, es construeix una matriu de confusió contrastant els resultats predits i els resultats coneguts del set d'entrenament. A partir d'aquesta matriu és possible estimar la precisió del model construït.

```{r}
# Matriu de confusió.
confMat_train <- table(titanic_train_clean$Survived, train_prediction)
# Càlcul de la precisió del model.
accuracy_tree <- sum(diag(confMat_train))/sum(confMat_train)
cat("El model d'arbre de decisió té una precisió del", round(accuracy_tree*100, 2),"% pel conjunt d'entrenament")
```

Com es pot observar, el model construit és considerablement robust, per la qual cosa es pot concloure en una primera aproximació que l'arbre de decisió és suficientment discriminatori.

Finalment, s'efectua anàlogament la predicció de la variable `Survived` pel subconjunt de prova o testing set. Es mostra un breu fragment de la predicció realitzada.

```{r}
# Predicció pel test.
test_prediction <- predict(tree, titanic_test_clean[,c("Survived", "Age", "Fare", "Sex_Numeric", "Embarked_Numeric", "Pclass")], type = 'class')
titanic_test_clean$Survived <- test_prediction
# Fem la còpia del DF titanic_test_clean
titanic_test_tree <- titanic_test_clean
# Transformem Died en 0 i Survived en 1
titanic_test_tree$Survived <- as.character(titanic_test_tree$Survived)
titanic_test_tree$Survived[titanic_test_tree$Survived=="Died"] <- "0"
titanic_test_tree$Survived[titanic_test_tree$Survived=="Survived"] <- "1"
titanic_test_tree$Survived <- as.factor(titanic_test_tree$Survived)
# Inspecció del resultat.
head(titanic_test_tree[, c("Survived", "Age", "Fare", "Sex_Numeric", "Embarked_Numeric")], 8)
```

Addicionalment, es presenta a continuació la corba ROC (*Receiver Operating Characteristic*), la qual presenta una primera idea gràfica de la capacitat de discriminació del model: mentre més s'aproxima a la cantonada superior esquerra més discriminant és, mentre que el cas contrari seria que el gràfic presentés una corba totalment plana prop de la diagonal. A més a més, es calcularà també l'àrea sota la corba AUROC (*Area Under the ROC*).

```{r roc tree}
# Canvi de format de la predicció.
train_prediction <- ifelse(train_prediction == "Died",
                           0,
                           1)
# Construcció de la corba ROC.
roc <- roc(titanic_train_clean$Survived,
           train_prediction,
           data = titanic_train_clean)
# Representació de la corba ROC.
plot(roc)
# Càlcul de AUROC.
roc
```

Els resultats obtinguts mostren una corba ROC que, en un primer anàlisi visual, sembla considerablement bona. El càlcul de l'AUROC efectuat confirma aquesta primera hipòtesi, ja que a partir d'un llindar de 0.8 es pot considerar que el model discrimina d'una forma excel·lent.

### 4.3.3. Model de regressió logística

Finalment, es construirà un model de regressió logística amb la finalitat de predir si els passatgers van sobreviure o no en funció de les variables de les quals es disposa.

El primer pas a dur a terme en la construcció del model és el de trobar les variables que resultin significatives. A partir del test de Wald, observant els valors obtinguts per l'estadísic de Wald (*z value*) i el seu p-valor associat ($Pr(>|z|)$), serà immediat comprovar si aquest últim és menor al nivell de significació del test (per defecte $\alpha=0.05$). D'aquesta manera, es podrà concloure que es tracta d'una variable significativa per l'ajust.

```{r logreg}
# Construcció del model.
reg_log <- glm(Survived ~ Age + Sex_Numeric + Fare + Pclass + Embarked_Numeric,
               data = titanic_train_clean,
               family = binomial(link = logit))
summary(reg_log)
# Odds ratio.
exp(coefficients(reg_log))
```

Com es pot observar, l'única variable que pel test de Wald ha resultat no ser significativa ha estat `Fare`, presentant un *p-value* de 0.85. Per tant, aquesta variable no serà considerada alhora de construir el model amb el qual es duran a terme les prediccions sobre el test de prova. Addicionalment, els *odds ratio* o OR calculats per cadascuna de les variables mostren aquelles que són de protecció (OR<1) i aquelles que són variables de risc (OR>1).

Un cop construït el model final de regressió logística s'efectuarà la predicció de la variable Survived pel subconjunt d'entrenament, fet que permetrà avaluar la precisió del model i les seves prediccions. Com que el model permet obtenir una probabilitat de supervivència, es considerarà `Survived=1` tota probabilitat igual o superior a 0.5.

```{r logreg final}
# Construcció del model FINAL.
reg_log <- glm(Survived ~ Age + Sex_Numeric + Pclass + Embarked_Numeric,
               data = titanic_train_clean,
               family = binomial)
summary(reg_log)
# Odds ratio.
exp(coefficients(reg_log))
# Predicció.
pred_train <- ifelse(predict(reg_log, titanic_train_clean, type = "response")<0.5,
                     0,
                     1)
# Precisió de la predicció.
confMat_train <- table(titanic_train_clean$Survived,
                       pred_train)
accuracy_reg <- sum(diag(confMat_train))/sum(confMat_train)
cat("\nEl model de regressió logística té una precisió del",
    round(accuracy_reg*100, 2),"% pel conjunt d'entrenament.")
```

Es procedirà de manera anàloga per tal d'efectuar la predicció pels registres del subset de prova o testing set.

```{r test prediction}
# Predicció.
reg_log_test_prediction <- predict(reg_log,
                           titanic_test_clean[,c("Survived", "Age",
                                                 "Sex_Numeric",
                                                 "Embarked_Numeric","Pclass")],
                           type = 'response')
# Assignació de valors.
titanic_test_clean$Survived <- ifelse(reg_log_test_prediction < 0.5,
                                      0,
                                      1)
# Fem la còpia del DF titanic_test_clean
titanic_test_regLog <- titanic_test_clean
# Transformem la variable Survived a factor
titanic_test_regLog$Survived <- as.factor(titanic_test_regLog$Survived)
# Inspecció dels registres.
head(titanic_test_clean[, c("Survived", "Age",
                            "Fare", "Sex_Numeric",
                            "Embarked_Numeric","Pclass")])
```

Es presenta a continuació la corba ROC pel model de regressió construït. A més a més, es calcula també l'àrea sota la corba AUROC per aquest cas.

```{r glm ROC}
# Construcció de la corba ROC.
roc <- roc(titanic_train_clean$Survived,
           pred_train,
           data = titanic_train_clean)
# Corba ROC.
plot(roc)
# AUROC.
roc
```

La figura mostra que el model és considerablement discriminant en una primera estimació visual, mentre que el valor obtingut per l'AUROC, d'aproximadament 0.78, permet assgurar que hem acoseguit un model que discrimina de forma adequada i ens trobem molt prop d'un model que discrimina de forma excel·lent, el qual correspon a un AUROC mínim de 0.8.

# 5. Representació dels resultats

A partir dels resultats obtinguts, les representacions en forma de taules i gràfics més interessants són aquelles que permeten avaluar la precisió dels dos models construïts a l'apartat anterior. En ambdós casos es mostrarà la matriu de confusió i una representació gràfica d'aquesta que permet que el resultat de les prediccions s'observi d'una forma molt més visual.

## 5.1. Arbre de decisió

```{r rep tree}
# Matriu de confusió.
(confMatrixTree <- table(titanic_train_clean$Survived, train_prediction))

# Representació gràfica.
fourfoldplot(confMatrixTree,color = c("#CC6666", "#99CC99"),
             conf.level = 0, margin = 1, main = "Matriu de confusió")
```

## 5.2. Regressió logística

```{r rep glm}
# Matriu de confusió.
(confMatrixGLM <- table(titanic_train_clean$Survived, pred_train))

# Representació gràfica.
fourfoldplot(confMatrixGLM,color = c("#CC6666", "#99CC99"),
             conf.level = 0, margin = 1, main = "Matriu de confusió")
```

## 5.3. Extracció de fitxers per la competició de Kaggle

En aquest cas l'exercici ens demana que extraiem un arxiu `csv` amb la nostra predicció pel conjunt de test. Així doncs, procedim a la creació de la funció que ens permeti extreure aquest arxiu per tal de presentar-lo com a resultat del nostre treball, i que pugui ser evaluat com en la competició de Kaggle **Titanic - Machine Learning from Disaster**.

```{r}
# Creem el fitxer csv amb el resultat de l'arbre.
write.csv(titanic_test_tree[, c("PassengerId", "Survived")], "Tree Model.csv", row.names = FALSE)
# Creem el fitxer csv amb el resultat de la regressió logística.
write.csv(titanic_test_regLog[, c("PassengerId", "Survived")], "Logistic Regression Model.csv", row.names = FALSE)
```

# 6. Conclusions

Al llarg dels diferents mètodes d'anàlisi aplicats en aquest estudi, s'ha procurat comprendre quina és l'estructura de les dades que composen el dataset utilitzat i, en base a l'enteniment guanyat, s'ha procedit a la construcció de models de predicció i/o classificació amb les dades del subset d'entrenament que permetessin predir el resultat de la variable de resposta `Survived` al subset de prova.

Primerament, s'ha construït una matriu de correlació amb les variables que s'han considerat rellevants amb la finalitat d'entendre com aquestes es troben interrelacionades entre si, amb l'objectiu de detectar possibles redundàncies i incongruències que permetessin ajustar d'una manera més òptima la informació de la qual es disposava. S'ha observat que l'única correlació estreta que era destacable de la matriu de correlació de Pearson construïda era l'existent entre `Pclass` i `Fare`, un resultat lògic tenint en compte que el preu d'entrada al vaixell ha d'estar directament relacionat amb la classe en la qual viatjava el passatger. Tot i el resultat obtingut, s'ha decidit seguir considerant ambdues variables en la construcció de models degut a que no suposava un gran cost computacional.

A continuació, s'han utilitzat algorismes supervisats, un d'arbre de decisió o *Decision Tree* i un de regressió logística, per tal de construir un model que permetés predir el resultat de la variable de resposta al subset de prova. Ambdós mètodes han resultat satisfactoris en obtenir un 82.49% i un 79.01% de precisió, respectivament. En els dos casos s'han utilitzat les mateixes variables (`Age`, `Sex_Numeric`, `Embarked_Numeric` i `Pclass`), i en el cas de l'arbre de decisió també `Fare`, tot i que per la regressió logística aquesta variable no resultava significativa.

El resultat més precís obtingut, el de l'arbre de decisió, mostra que les variables més significatives a l'hora de determinar si un determinat passatger sobreviurà o no a l'accident del Titanic són el sexe, l'edat, la tarifa i la classe (`Sex_Numeric`, `Age`, `Fare` i `Pclass`), essent el sexe la més determinant de totes. Això ho podem associar al fet que els primers passatgers que van ser evacuats van ser infants i dones.

Finalment, cal esmentar que s'ha participat al concurs de Kaggle amb les dues prediccions generades a partir dels seus respectius models. Les puntuacions obtingudes han estat d'un 77.033% en el cas de l'arbre de decisió i un 75.119% en el cas de la regressió logística, tal com es pot observar a la següent figura.

![](kaggle_score.jpg)

# 7. Quadre 

Finalment, presentarem el quadre de col·laboracions i el farem amb la llibreria Kable.
```{r}
# Quadre de contribucions amb la llibreria Kable
out <- data.frame(Contribucions = c("Descripció del Dataset", "Integració i selecció de dades", "Neteja de dades", "Anàlisi de dades", "Representació dels resultats", "Resolució del problema", "Codi", "Conclusions"),
                  Firma = c("Guillem Fernández i Miquel Tomé", "Guillem Fernández i Miquel Tomé", "Guillem Fernández i Miquel Tomé", "Guillem Fernández i Miquel Tomé", "Guillem Fernández i Miquel Tomé", "Guillem Fernández i Miquel Tomé", "Guillem Fernández i Miquel Tomé", "Guillem Fernández i Miquel Tomé"))

out %>% kable() %>% kable_styling()
```
                  